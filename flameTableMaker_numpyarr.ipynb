{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a70147a-018f-4ab0-b22e-5f944030fc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.integrate import quad\n",
    "import os\n",
    "from glob import glob\n",
    "from re import match, search\n",
    "from statistics import variance\n",
    "import matplotlib.pyplot as plt\n",
    "import LiuInt as LI #Package with functions for integrating over the BPDF, parameterized by xi_avg and xi_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00e431fd-16d9-4a73-8427-9a13fefb5de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_progress_variable(Tdata, header, components = ['H2', 'H2O', 'CO', 'CO2']):\n",
    "    \"\"\"\n",
    "    Progress variable is defined as the sum of the mole fractions of a specified set of components.\n",
    "    Computes progress variable using:\n",
    "        Tdata = Transposed data from get_data_files. Each row corresponds to a specific property. \n",
    "            ex. Tdata[0] = array of temperature data\n",
    "        header = array of column headers, denoting which row in Tdata corresponds to which property\n",
    "            ex. If header[0] = \"Temp\", then Tdata[0] should be temperature data.\n",
    "        \n",
    "    \"\"\"\n",
    "    indices = np.empty(len(components), dtype = np.int8)\n",
    "    \n",
    "    # -------- Determine where the components are the Tdata\n",
    "    for i in range(len(header)):\n",
    "        for y in range(len(components)):\n",
    "            if header[i].lower()==components[y].replace(\" \",\"\").lower():\n",
    "                indices[y] = int(i)         #Indices must be strictly integers (ex. 5, not 5.0)\n",
    "\n",
    "    c = np.zeros(len(Tdata[0]))                #Initialize c array\n",
    "    for d in range(len(Tdata[0])):          #For each set of data points (each column),\n",
    "        sum = 0\n",
    "        for index in indices:\n",
    "            #print(indices)\n",
    "            #print(d)\n",
    "            sum += Tdata[index,d]          #Sum the mole fractions of each component\n",
    "        c[d] = sum\n",
    "    return c "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7674797-836a-46d1-9aef-44858c08e644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.03422306, 0.06840554, 0.0976334 , 0.12349997,\n",
       "       0.14680362, 0.16798934, 0.18734565, 0.20507326, 0.22128368,\n",
       "       0.23594244, 0.248739  , 0.25899119, 0.26602212, 0.26996978,\n",
       "       0.27174114, 0.27225077, 0.27208599, 0.27155841, 0.27082056,\n",
       "       0.26994678, 0.26897569, 0.26792947, 0.26682214, 0.26566321,\n",
       "       0.26144952, 0.25316058, 0.24404994, 0.23416185, 0.22347239,\n",
       "       0.21193404, 0.19948689, 0.18605951, 0.17157281, 0.15593357,\n",
       "       0.13899224, 0.12052713, 0.10024229, 0.07768588, 0.05204542,\n",
       "       0.02159446, 0.        ])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_data_files(path_to_flame_data):\n",
    "    \"\"\"\n",
    "    Grabs and formats the data outputted by the flame code (ignite.byu.edu), then exports an array with the following:\n",
    "        all_data = dictionary with the data from each file indexed using the filename as the key. \n",
    "            - Indexed using all_data[fileName (string)][column# = Property][row # = data point]\n",
    "        headers = dictionary with the column labels indexed using the filename as the key.\n",
    "            - All indices should be the same for a given instance of the flame code, but all headers have been redundantly included.\n",
    "        extras = dictionary with the extra information included at the beginning of a data file, indexed using the filename as the key.\n",
    "            - This data is included in unformatted form.\n",
    "    \"\"\"\n",
    "    #---------- Check if the provided path is a valid directory\n",
    "    if not os.path.isdir(path_to_flame_data):\n",
    "        print(f\"Error: {path_to_flame_data} is not a valid directory.\")\n",
    "        return None\n",
    "    \n",
    "    #---------- Define regex to grab only data files\n",
    "    file_pattern = r'^L.*\\.dat$'\n",
    "    \n",
    "    #---------- Use glob to list all files in the directory\n",
    "    files = glob(os.path.join(path_to_flame_data, '*'))\n",
    "    \n",
    "    #---------- Store data in a dictionary with the filename as the key\n",
    "    data_files = {os.path.basename(file): file for file in files if match(file_pattern, os.path.basename(file))}\n",
    "\n",
    "    #---------- Initialize data arrays\n",
    "    all_data = {}    #initialize to grab data values\n",
    "    headers = {}     #Initialize to store headers\n",
    "    extras = {}      #initialize to store extra info before header\n",
    "\n",
    "    #---------- Grab and store data\n",
    "    for key in data_files.keys():\n",
    "        file = data_files[key]\n",
    "        with open(file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            data = np.array([line.strip() for line in lines if not line.startswith('#')])\n",
    "\n",
    "            #---------- Grab the header and extra data (included as commented lines and column labels)\n",
    "            IsHeader = True\n",
    "            header = np.array([])\n",
    "            extra = np.array([])\n",
    "            for line in reversed(lines):               #The last of the commented lines should be the actual headers,\n",
    "                if line.startswith('#'):               # so we take the first of the lines when read in reverse order\n",
    "                    vals = np.array([val for val in line.strip().split() if val !='#'])\n",
    "                    if IsHeader == True:\n",
    "                        for val in vals:\n",
    "                            #Remove preemtive numbers in the column labels, then store column label\n",
    "                            #This is used later to select which column of data to use when creating the table\n",
    "                            header = np.append(header, val.split(\"_\")[1])\n",
    "                        IsHeader = False               #The next line won't be the header, but should be stored in 'extras'\n",
    "                    else:\n",
    "                        for val in vals:\n",
    "                            extra = np.append(extra, val)\n",
    "                            \n",
    "        header = np.append(header, \"c\")                #Adds a column label for progress variable (handled below)\n",
    "        headers[key] = header\n",
    "        extras[key] = extra\n",
    "        \n",
    "        #---------- Parse out numerical values\n",
    "        file_data = np.empty(len(data[0].split()))     # will hold the data for this file\n",
    "        \n",
    "        for row in data:\n",
    "            numbers = np.array([float(val) for val in row.split()])\n",
    "            file_data = np.vstack((file_data,numbers)) #Adds each new row of data as a new row in file_data\n",
    "        file_data = file_data[1:file_data.size]        #Get rid of first column (which is empty and only used for initialization)\n",
    "\n",
    "        #---------- Transpose data so that each property has it's own list (ex. one list is temperature data, one is density, etc.)\n",
    "        transposed_file_data = file_data.T\n",
    "\n",
    "        #---------- Add a row with progress variable (c)\n",
    "        c = compute_progress_variable(transposed_file_data, header)   #Gets an array of values of progress variable across the domain\n",
    "        transposed_file_data = np.vstack((transposed_file_data, c))   #Stacks this array of progress variable values as the last row \n",
    "        \n",
    "        #---------- Arrange data in a dictionary: all_data[fileName][propertyIndex][data_point]\n",
    "        all_data[key] = transposed_file_data\n",
    "        \n",
    "    #all_data is indexed using all_data[fileName (string)][column# = Property][row # = data point]\n",
    "    return all_data, headers, extras\n",
    "test = get_data_files(\"../flame/run\")[0][\"L_0.004U_008.dat\"]\n",
    "test[len(test)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88ea1ae2-f7bd-4fda-85c1-b9eccf3cbc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phiFuncs(path_to_flame_data, phi = 'T', fileName = False):\n",
    "    \"\"\"\n",
    "    Uses the given path to directory holding data outputted from the flame code (ignite.byu.edu) to grab these datafiles \n",
    "    and return an array of interpolated functions phi(ξ).\n",
    "    Inputs:\n",
    "        path_to_flame_data = the path on the local machine pointing to the flame code's main directory\n",
    "        fileName = If set to false, the output will be an array of the functions phi(ξ) for all datafiles. Otherwise, this determines\n",
    "            which specific file should be used. \n",
    "            Example1: phiFuncs(path, phi = 'T', fileName = 'L_0.002U_1.dat'): returns the interpolated T(ξ) function from L_0.002U_1.dat ONLY\n",
    "            Example2: phiFuncs(path, phi = 'T'): returns an array containing the interpolated T(ξ) functions from each file in the directory\n",
    "        phi = desired property (ex. Temperature, density, etc.) Available phi are viewable as get_data_files(params)[1]\n",
    "            NOTE: c (progress variable) may be selected. Currently, c ≡ y_CO2 + y_CO + y_H2O + yH2\n",
    "    Outputs:\n",
    "         The output type of phiFuncs will depend on the parameter fileName:\n",
    "             - If fileName is left as False, the output will be a dictionary of functions (file names as keys)\n",
    "             - If fileName is specified, the output will be the function object for that specific file only. \n",
    "    \"\"\"\n",
    "    #---------- Import data, files, and headers\n",
    "    data, headers, extras = get_data_files(path_to_flame_data)\n",
    "    \n",
    "    #---------- Get list of available phi (list of all data headers from original files)\n",
    "    if type(fileName) == bool:\n",
    "        #This assumes all datafiles have the same column labels and ordering\n",
    "        phis = headers[list(headers)[0]] \n",
    "    else:\n",
    "        phis = headers[fileName]\n",
    "    \n",
    "    #---------- Interpret user input for \"phi\", find relevant columns\n",
    "    phi_col = -1\n",
    "    xi_col = -1\n",
    "    \n",
    "    for i in range(len(phis)):\n",
    "        if phis[i].lower()==phi.replace(\" \",\"\").lower():\n",
    "            phi_col = i\n",
    "        if phis[i].lower()==\"mixf\":\n",
    "            xi_col = i\n",
    "    if phi_col == -1:\n",
    "        raise ValueError(\"{} not recognized. Available phi are:\\n {}\".format(phi, phis))\n",
    "        return None\n",
    "    if xi_col == -1:\n",
    "        raise ValueError(\"Mixture fraction ('mixf') was not found among data columns.\")\n",
    "        return None\n",
    "\n",
    "    #---------- Interpolate phi(xi)\n",
    "    phiFuncs = {}\n",
    "    if type(fileName) == bool:\n",
    "        #Have to interpolate for every file\n",
    "        for key in data.keys():\n",
    "            xis = data[key][xi_col]\n",
    "            phis = data[key][phi_col]\n",
    "            func = interp1d(xis, phis, kind = 'cubic')\n",
    "            phiFuncs[key] = func\n",
    "        return phiFuncs\n",
    "    else:\n",
    "        xis = data[fileName][xi_col]\n",
    "        phis = data[fileName][phi_col]\n",
    "        func = interp1d(xis, phis, kind = 'cubic')\n",
    "        return func\n",
    "\n",
    "    raise ValueError(\"Error in code execution: no functions were returned.\")\n",
    "    return None #Code should never reach here\n",
    "\n",
    "#phiFuncs(\"../flame/run\", fileName = 'L_0.002U_24.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a4067d-8a12-4bad-8241-9b081feda23f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Testing Grounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22c920bd-b38f-4c2d-94a9-e21bfbc06aa9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'L_0.002U_24.dat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Fidelity Test: trying to determine the behavior of the BetaPDF near 0 and 1\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mLiuInt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mLI\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m function \u001b[38;5;241m=\u001b[39m \u001b[43mphiFuncs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../flame/run\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mT\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfileName\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mL_0.002U_24.dat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#For what value of xim is xim = 0 = x a good approximation? \u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#Hypothesis: Something beneath 1e-6 will work fine. \u001b[39;00m\n\u001b[1;32m      7\u001b[0m Min \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[0;32mIn[4], line 26\u001b[0m, in \u001b[0;36mphiFuncs\u001b[0;34m(path_to_flame_data, phi, fileName)\u001b[0m\n\u001b[1;32m     24\u001b[0m     phis \u001b[38;5;241m=\u001b[39m headers[\u001b[38;5;28mlist\u001b[39m(headers)[\u001b[38;5;241m0\u001b[39m]] \n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 26\u001b[0m     phis \u001b[38;5;241m=\u001b[39m \u001b[43mheaders\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfileName\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m#---------- Interpret user input for \"phi\", find relevant columns\u001b[39;00m\n\u001b[1;32m     29\u001b[0m phi_col \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'L_0.002U_24.dat'"
     ]
    }
   ],
   "source": [
    "# Fidelity Test: trying to determine the behavior of the BetaPDF near 0 and 1\n",
    "import LiuInt as LI\n",
    "function = phiFuncs(\"../flame/run\", 'T', fileName = 'L_0.002U_24.dat')\n",
    "\n",
    "#For what value of xim is xim = 0 = x a good approximation? \n",
    "#Hypothesis: Something beneath 1e-6 will work fine. \n",
    "Min = -1\n",
    "xim = np.logspace(0, Min,10)\n",
    "xiv = np.logspace(0, Min,10)\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker, cm\n",
    "  \n",
    "# Creating 2-D grid of features \n",
    "[X, Y] = np.meshgrid(xim, xiv) \n",
    "  \n",
    "fig, ax = plt.subplots(1, 1) \n",
    "\n",
    "Z = np.zeros((len(xim), len(xiv)))\n",
    "for i in range(len(xim)):\n",
    "    for j in range(len(xiv)):\n",
    "        Z[i,j] = LI.IntegrateForPhiBar(xim[i], xiv[j], function)\n",
    "\n",
    "# plots filled contour plot \n",
    "ax.contourf(X, Y, Z) \n",
    "  \n",
    "ax.set_title('Predicted values') \n",
    "ax.set_xlabel('Xim') \n",
    "ax.set_xscale('log')\n",
    "ax.set_ylabel('Xiv')\n",
    "ax.set_yscale('log')\n",
    "cs = ax.contourf(X, Y, Z, locator=ticker.LogLocator(), cmap=cm.PuBu_r)\n",
    "cbar = fig.colorbar(cs)\n",
    "  \n",
    "plt.show() \n",
    "plt.savefig('Fidelity_min.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9207ee4-d4b8-4db5-b193-46b647ff6739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bab24d34e9d489ea4c4be38e32ef482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.50000000005, description='xim', max=1.0, min=1e-10), FloatSlider(val…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TO DO: Create BPdf plotting widget to visualize the effect of xim and xiv\n",
    "import ipywidgets as wgt\n",
    "import LiuInt as LI\n",
    "def f(xim, xiv):\n",
    "    xis = np.linspace(0,1, 1000)\n",
    "    y = LI.βPdf(xis, xim, xiv)\n",
    "    plt.plot(xis, y)\n",
    "    plt.show()\n",
    "    #print(\"Xiv max = \", xim*(1-xim))\n",
    "\n",
    "wgt.interact(f, xim=(1e-10,1), xiv=(1e-10,0.5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996600a7-90c2-4da9-81f4-6622634ebd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing Grounds\n",
    "\n",
    "#Array masking\n",
    "a = np.ones(10)*(-1)\n",
    "for i in range(len(a)-1):\n",
    "    a[i] = np.random.rand()\n",
    "aNew = a[a!=-1]\n",
    "\n",
    "#Regex\n",
    "pattern = r\"L_([\\d.]+)[SU]_([\\d.]+)\\.dat\"\n",
    "candidates = [\"L_0.03U_198.dat\", \"L_0.002S_299.dat\", \"L0990U900.dat\"]\n",
    "for c in candidates:\n",
    "    print(search(pattern, c))\n",
    "\n",
    "L = 0.03\n",
    "pattern2 =  f\"L_{L}[SU]_[\\d]*\\.dat\"\n",
    "arr2 = [\"L_0.02S_001.dat\", \"L_0.02S_003.dat\", \"L_0.02S_002.dat\", \"L_0.02U_001.dat\", \"L_0.03S_001.dat\"]\n",
    "print(\"Here\", len([name for name in arr2 if match(pattern2, name)]))\n",
    "arr = [0.1, 0.4, 0.5, 0.2, 0.7, 0.15]\n",
    "print(np.sort(arr)[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae63137d-5e66-4864-880d-896d655acbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array([i for i in range(10)]))\n",
    "print(np.arange(0,10,1))\n",
    "US = ['U', 'S']\n",
    "t = 4\n",
    "print(US[t != 0])\n",
    "print(\"0\"*(3-len(str(2))))\n",
    "print(np.zeros((5,5)))\n",
    "car = {\n",
    "  \"brand\": \"Ford\",\n",
    "  \"model\": \"Mustang\",\n",
    "  \"year\": 1964\n",
    "}\n",
    "print(list(car))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cf0efe-10d9-40b2-8ec1-b7620f8ab6db",
   "metadata": {},
   "source": [
    "# Making the Table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dd16dd5-18fb-4042-9ba4-3229c6105b07",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def makeLookupTable(path_to_flame_data, phi, numXim=5, numXiv = 5):\n",
    "    \"\"\"\n",
    "    Creates a 4D lookup table of phi_avg data from inputted data files. Axis are ξm, ξv, length scale, and time step\n",
    "    Inputs:\n",
    "        path_to_flame_data = path to the folder containing data resulting from running the flame code (ignite.byu.edu)\n",
    "        phi = property for which values will be tabulated. List of available phi for each file can be obtained using the following:\n",
    "            get_data_files(path_to_flame_data)[1][fileName]\n",
    "        numXim, numXiv: Number of data points between bounds for ξm and ξv, respectively. Default value: 5\n",
    "    \"\"\"\n",
    "    \n",
    "    funcs = phiFuncs(path_to_flame_data, phi)\n",
    "\n",
    "    #---------- Create arrays of ξm and ξv\n",
    "    Xims = np.linspace(0,1,numXim) #debugging\n",
    "        #Xim = Mean Mixture Fraction cannot be 0 or 1 because of BPDF parameterization.\n",
    "    Xivs = np.zeros((len(Xims),numXiv))\n",
    "    for i in range(len(Xivs)):\n",
    "        Xivs[i] = np.linspace(0, Xims[i]*(1-Xims[i]), numXiv)\n",
    "\n",
    "    #----------- Get array of unique L values\n",
    "    pattern = r\"L_([\\d.]+)[SU]_([\\d.]+)\\.dat\"\n",
    "    keys = list(funcs)                              #keys is an array of the available file names\n",
    "    LsAvail = np.ones(len(keys))*(-1)               #LsAvail is an empty array for storing vaues of L. In the worst case, each L is unique. \n",
    "    for i in range(len(keys)):\n",
    "        result = search(pattern, keys[i])           #Use regex to grab lengths and times\n",
    "        if result != None:\n",
    "            new = True\n",
    "            for L in LsAvail:\n",
    "                if float(result.group(1)) == L:\n",
    "                    new = False  \n",
    "            if new:\n",
    "                LsAvail[i] = float(result.group(1)) #List of unique available Ls\n",
    "    Ls = LsAvail[LsAvail != -1]                     #Trims away unused slots. \n",
    "    Ls = np.sort(Ls)[::-1]                          #Sorts array in descending numerical order (order that the flames were computed)\n",
    "    \n",
    "    #----------- Get the number of time steps:\n",
    "    pattern2 =  f\"L_{Ls[1]}[SU]_[\\d]*\\.dat\"         #Uses the second L since the first L uses 'IC.dat'\n",
    "    tlen = len([name for name in keys if match(pattern2, name)])\n",
    "    ts = np.arange(0, tlen, 1)\n",
    "    \n",
    "    #----------- Table Creation\n",
    "    table = np.full((numXim, numXiv, len(Ls), tlen), -1.0)\n",
    "    for m in range(len(Xims)):                                             #Loop over each value of ξm\n",
    "        xim = Xims[m]\n",
    "        for v in range(len(Xivs[m])):                                      #Loop over each value of ξv\n",
    "            xiv = Xivs[m][v]\n",
    "            for l in range(len(Ls)):                                       #Loop over each length scale (j)\n",
    "                L = Ls[l]\n",
    "                for t in range(len(ts)):                                   #Loop over each time step (k)\n",
    "                    SU = ['S', 'U']                                        #If t = 0, this should be S. Otherwise, it should be U\n",
    "                    zeros = \"0\"*(3-len(str(ts[t])))                        #Adds correct amount of padding zeros\n",
    "                    nameGuess = f\"L_{L}{SU[t != 0]}_{zeros}{ts[t]}.dat\"    #Creates the filename as a string\n",
    "                    if nameGuess in keys:\n",
    "                        function = funcs[nameGuess]                        #Grab corresponding phi(xi) function\n",
    "                        phiAvg = LI.IntegrateForPhiBar(xim, xiv, function) #Calculates phi__Avg\n",
    "                        table[m,v,l,t] = phiAvg                            #FINAL INDEXING: table[m,v,l,t]\n",
    "                    elif l != 0:                                           #Function didn't have steady-state, so use previous conditions.\n",
    "                        nameGuess2 = f\"L_{Ls[l-1]}S_000.dat\"               #Try to find steady-state data for previous L\n",
    "                        if nameGuess2 in keys:\n",
    "                            function = funcs[nameGuess2]                   \n",
    "                            phiAvg = LI.IntegrateForPhiBar(xim, xiv, function)\n",
    "                            table[m,v,l,t] = phiAvg                        #FINAL INDEXING: table[m,v,l,t]\n",
    "                        else:\n",
    "                            #For debugging\n",
    "                            print(f\"\"\"ERROR: No valid steady state found for L = {L} \n",
    "                            Initially tried to find {nameGuess} in files but failed.\n",
    "                            Then tried to find {nameGuess2} in files and failed.\n",
    "                            m, v, l, t = {m} {v} {l} {t}\"\"\")\n",
    "                            \n",
    "    #Returns: table itself, then an array of the values of Xims, Xivs, Ls, and ts for indexing the table.\n",
    "        #Ex. table[1][2][3][4] corresponds to Xim = Xims[1], Xiv = Xivs[1][2], L = Ls[3], t = ts[4].\n",
    "        #Note that because each Xim has a different set of corresponding Xivs, Xivs is 2D\n",
    "    indices = [Xims, Xivs, Ls, ts]\n",
    "    return table, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abb9da9d-d15f-485c-a63b-ab27a9b20eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaredwp91/Research/mnt/inferno/codes/TableMaker/post/LiuInt.py:34: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  norm = gamma(a+b)/gamma(a)/gamma(b)   # Normalizes PDF to integrate to 1\n",
      "/home/jaredwp91/Research/mnt/inferno/codes/TableMaker/post/LiuInt.py:54: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
      "  p2 = quad(ϕP, ϵ, 1-ϵ)[0]             # ϵ < ξ < 1-ϵ\n",
      "/home/jaredwp91/Research/mnt/inferno/codes/TableMaker/post/LiuInt.py:54: IntegrationWarning: The integral is probably divergent, or slowly convergent.\n",
      "  p2 = quad(ϕP, ϵ, 1-ϵ)[0]             # ϵ < ξ < 1-ϵ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed = 72.55 seconds\n"
     ]
    }
   ],
   "source": [
    "#Table Test                \n",
    "import time\n",
    "\n",
    "phi = 'T'\n",
    "start = time.process_time()\n",
    "table, indices = makeLookupTable(\"../flame/run\", phi)\n",
    "elapsed = (time.process_time()-start)\n",
    "print(f\"Time elapsed = {elapsed:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfba8bbd-ce73-4af5-913c-cbf38704bea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valToIndex(xim, xiv, L, t, indices, thresh = 1e-4):\n",
    "    \"\"\"\n",
    "    Converts values of Xim, Xiv, L, and t to indices for the table resulting from the lookupTable function.\n",
    "    Inputs:\n",
    "        xim = value of Xim\n",
    "        xiv = value of Xiv\n",
    "        L = value of length scale\n",
    "        t = value of time step\n",
    "        indices = second output array of lookupTable\n",
    "        thresh: Accounts for marginal roundoff error due to linspace\n",
    "            For example, inputting xiv = 0.0045 in this function will match with tabulated xiv values 0.0045 +- thresh\n",
    "    Outputs are the indices of the relevant value. For example:\n",
    "        i_Xim = index of the inputted Xim value in the lookup table\n",
    "    \"\"\"\n",
    "    i_Xim = \"err: val not found\"\n",
    "    i_Xiv = \"err: val not found\"\n",
    "    i_L = \"err: val not found\"\n",
    "    i_t = \"err: val not found\"\n",
    "\n",
    "    for x in range(len(indices[0])):\n",
    "        if (indices[0][x]-xim) <= thresh:\n",
    "            i_Xim = x\n",
    "            for y in range(len(indices[1][i_Xim])):\n",
    "                if (indices[1][x][y]-xiv) <= thresh:\n",
    "                    i_Xiv = y\n",
    "    for z in range(len(indices[2])):\n",
    "        if indices[2][z] == L:\n",
    "            i_L = z\n",
    "    for time in range(len(indices[3])):\n",
    "        if indices[3][time] == t:\n",
    "            i_t = time\n",
    "    return i_Xim, i_Xiv, i_L, i_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf967cb-8178-4cd1-8067-ea2fbbc234e4",
   "metadata": {},
   "source": [
    "# Evaluate L,t -> h,c remapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e17f48e7-bfbe-4301-84b7-6c22b9fdf84f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91cadad4bab94388833203762fd1c59a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=45, description='theta', max=90), IntSlider(value=180, description='phi'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mpl_toolkits import mplot3d\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import ipywidgets as wgt\n",
    "\n",
    "def interact(theta, phi):\n",
    "    #Temperature in terms of l and t\n",
    "    def f(l, t):\n",
    "        ij = valToIndex(-1,-1,l,t, indices)\n",
    "        i = ij[2]\n",
    "        j = ij[3]\n",
    "        return table[2][2][i][j] #Arbitrarily use the third value of xim and xiv\n",
    "    fvect = np.vectorize(f)\n",
    "    \n",
    "    x = indices[2] #Ls\n",
    "    y = indices[3] #ts\n",
    "    \n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    Z = fvect(X, Y)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes(projection='3d')\n",
    "    ax.plot_surface(X, Y, Z, rstride=1, cstride=1,\n",
    "                    cmap='viridis', edgecolor='none')\n",
    "    ax.set_xlabel('L')\n",
    "    ax.set_ylabel('t')\n",
    "    ax.set_zlabel('Temperature')\n",
    "    ax.set_title('Temp(L,t)')\n",
    "    ax.view_init(theta, phi)\n",
    "    plt.show()\n",
    "\n",
    "wgt.interact(interact, theta=(0,90), phi=(0,360));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a35eaa95-0023-4f66-8388-337d81c96fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "#----- Plot h(xim, xiv) and c(xim, xiv)\n",
    "# Get data for h and c:\n",
    "phi = 'h'\n",
    "h_table, h_indices = makeLookupTable(\"../flame/run\", phi)\n",
    "phi = 'c'\n",
    "c_table, c_indices = makeLookupTable(\"../flame/run\", phi)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101300d3-5f73-4055-9214-697d622518eb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### h, c visual interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c14bf014-9fec-4dc1-b5c7-e14e76f906e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40f9ca7db2634e84ba49cafd7f64ab61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=45, description='theta', max=90), IntSlider(value=180, description='phi'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hot colors are c, Cooler colors are h\n"
     ]
    }
   ],
   "source": [
    "def interact(theta, phi, l, t):\n",
    "    def h(xim, xiv):\n",
    "        ijko = valToIndex(xim, xiv, l, t, h_indices)\n",
    "        i = ijko[0]\n",
    "        j = ijko[1]\n",
    "        k = ijko[2]\n",
    "        o = ijko[3]\n",
    "        return h_table[i][j][k][o]\n",
    "    hvect = np.vectorize(h)\n",
    "\n",
    "    def c(xim, xiv):\n",
    "        ijko = valToIndex(xim, xiv, l, t, c_indices)\n",
    "        i = ijko[0]\n",
    "        j = ijko[1]\n",
    "        k = ijko[2]\n",
    "        o = ijko[3]\n",
    "        return c_table[i][j][k][o]\n",
    "    cvect = np.vectorize(c)\n",
    "\n",
    "    hxims = h_indices[0]\n",
    "    hxivs = h_indices[1]\n",
    "    cxims = c_indices[0]\n",
    "    cxivs = c_indices[1]\n",
    "\n",
    "    HXM, HXV = np.meshgrid(hxims, hxivs)\n",
    "    H = hvect(HXM, HXV)\n",
    "    CXM, CXV = np.meshgrid(cxims, cxivs)\n",
    "    C = cvect(CXM, CXV)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes(projection='3d')\n",
    "    ax.plot_surface(CXM, CXV, C, rstride=1,cstride=1,\n",
    "                    cmap='plasma', edgecolor='none')\n",
    "    ax.plot_surface(HXM, HXV, H, rstride=1,cstride=1,\n",
    "                    cmap = 'viridis', edgecolor='none')\n",
    "    ax.set_xlabel('Xim')\n",
    "    ax.set_ylabel('Xiv')\n",
    "    ax.set_zlabel(\"h or c\")\n",
    "    ax.set_title(\"h(Xim, Xiv) and c(Xim, Xiv)\")\n",
    "    ax.view_init(theta, phi)\n",
    "    plt.show()\n",
    "\n",
    "wgt.interact(interact, theta=(0,90), phi=(0,360), l = (0.02,0.02), t = (6,6))\n",
    "\n",
    "print(\"Hot colors are c, Cooler colors are h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f486ea0a-5e78-4fc0-ad31-c76aa860b01a",
   "metadata": {},
   "source": [
    "# Interpolating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6273f468-3ce0-420d-8b77-ca3ac7851c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.  , 0.25, 0.5 , 0.75, 1.  ]), array([[0.      , 0.      , 0.      , 0.      , 0.      ],\n",
      "       [0.      , 0.046875, 0.09375 , 0.140625, 0.1875  ],\n",
      "       [0.      , 0.0625  , 0.125   , 0.1875  , 0.25    ],\n",
      "       [0.      , 0.046875, 0.09375 , 0.140625, 0.1875  ],\n",
      "       [0.      , 0.      , 0.      , 0.      , 0.      ]]), array([0.2  , 0.04 , 0.02 , 0.008, 0.006, 0.004, 0.002]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10])]\n",
      "h test:\n",
      "5.178762038251512e-06\n",
      "5.178762038251512e-06\n",
      "1.1598725566299779e-06\n",
      "\n",
      "c test:\n",
      "0.19427089596079436\n",
      "0.19427089596079436\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(4.54836655e-06)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Because Xiv vs. Xim is not square, we have to interpolate using indices.\n",
    "def createInterpolator(data, inds):\n",
    "    from scipy.interpolate import RegularGridInterpolator as rgi\n",
    "    from scipy.interpolate import interp1d\n",
    "    from scipy.optimize import fsolve\n",
    "    \"\"\"\n",
    "    Accepts a table and indices created by makeLookupTable to create an \n",
    "    interpolator using RegularGridInterpolator\n",
    "    The returned function is called with func(xim, xiv, L, t)\n",
    "    \"\"\"\n",
    "    xi_means = inds[0]\n",
    "    xi_vars = inds[1] #2D array. xi_vars[i] has xiv values for xi_means[i]\n",
    "    \n",
    "    xi_mean_indices = range(len(xi_means))\n",
    "    xi_var_indices = range(len(inds[1][0])) #each row has the same # of xivs\n",
    "    # NOTE: Because each value of ximean has a different set of xivars, \n",
    "    # we must interpolate by index. We do the same with xi_mean itself. \n",
    "    Ls = inds[2]\n",
    "    ts = inds[3]\n",
    "    \n",
    "    interpolator = rgi((xi_mean_indices, xi_var_indices, Ls, ts), data)\n",
    "\n",
    "    def translate(xim, xiv):\n",
    "        \"\"\"\n",
    "        Translates xim and xiv values to their respective indices, \n",
    "        which are then used in the interpolator. \n",
    "        \"\"\"\n",
    "        xim_ind = interp1d(xi_means, xi_mean_indices, kind = 'cubic')(xim)\n",
    "\n",
    "        #xi_vars is 2D. xi_means[i] has the corresponding \n",
    "        #variances in xi_vars[i]. Thus:\n",
    "        interp = rgi((xi_mean_indices, xi_var_indices), xi_vars)\n",
    "        xiv_ind = fsolve(lambda index: interp((xim_ind, index)) - xiv, 0.01)[0]\n",
    "        return (xim_ind, xiv_ind)\n",
    "\n",
    "    def func(xim, xiv, l, t):\n",
    "        \"\"\"\n",
    "        Function returned to the user. Accepts values of Xi_mean, Xi_variance, \n",
    "        length, and time scale. \n",
    "        \"\"\"\n",
    "        xim_ind, xiv_ind = translate(xim, xiv)\n",
    "        return interpolator((xim_ind, xiv_ind, l, t))\n",
    "    \n",
    "    return func\n",
    "\n",
    "\n",
    "Ih = createInterpolator(h_table, h_indices)\n",
    "Ic = createInterpolator(c_table, c_indices)\n",
    "\n",
    "print(h_indices)\n",
    "\n",
    "print(\"h test:\")\n",
    "print(h_table[1][1][1][1])\n",
    "print(Ih(h_indices[0][1], h_indices[1][1][1], h_indices[2][1], h_indices[3][1]))\n",
    "print(Ih(0.5, 0.1, 0.1, 2))\n",
    "print()\n",
    "\n",
    "print(\"c test:\")\n",
    "print(c_table[1][1][1][1])\n",
    "print(Ic(c_indices[0][1], c_indices[1][1][1], c_indices[2][1], h_indices[3][1]))\n",
    "\n",
    "#SUCCESS!\n",
    "Ih(0.3, 0.1, 0.03, 2.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157c9bca-4daf-4ab7-883f-7512bf0b4798",
   "metadata": {},
   "source": [
    "# Benchmarking (unedited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaef3f5-631b-4147-af4f-757b5303b37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmarking\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "phi = 'T'\n",
    "times = np.zeros(8)\n",
    "for i in range(len(times)):\n",
    "    start = time.process_time()\n",
    "    table, indices = lookupTable(\"/home/jaredwp91/Research/mnt/inferno/codes/flameJWP/run\",\n",
    "                                phi, resolution = i+1)\n",
    "    t = (time.process_time() - start)\n",
    "    times[i] = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae206e0-1e8c-436d-ad60-a46237e4a3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "res = np.arange(1,9,1)\n",
    "plt.plot(res, times, '.', label = \"Observed Values\")\n",
    "plt.xlabel(\"Resolution\")\n",
    "plt.ylabel(\"Processing time (s)\")\n",
    "plt.title(\"Table Creation Time\")\n",
    "\n",
    "def func(x, a, b):\n",
    "    return a*x**2 + b*x\n",
    "p1, p2 = curve_fit(func, res, times)[0]\n",
    "\n",
    "lin = np.linspace(1,8,100)\n",
    "plt.plot(lin, func(lin, p1, p2), label = f\"t = ({p1:.2f}) r^2 + ({p2:.2f}) r\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3aee94-3762-4242-ab38-137574785dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Valid Xims and Xivs: {indices[1]}\")\n",
    "print()\n",
    "print(f\"Valid Ls and ts: {indices[3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1468027a-8894-4169-9db2-6d5e0c3879f2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a3b0a0a-ad19-4290-820d-7d9bb8a096d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average T from data in L_0.002U_009.dat (calculated directly) = 407.32 K\n",
      "Average T from data in L_0.002U_009.dat (tabulated)           = 406.88 K\n",
      "\n",
      "Filename             T_avg (calculated)        T_avg (tabulated)\n",
      "----------------------------------------------------------------\n",
      "L_0.2S_000.dat           1201.25 K                1215.25 K\n",
      "L_0.2U_001.dat           1144.85 K                1157.46 K\n",
      "L_0.2U_002.dat           1075.50 K                1086.47 K\n",
      "L_0.2U_003.dat           990.26 K                 999.30 K\n",
      "L_0.2U_004.dat           891.83 K                 898.82 K\n",
      "L_0.2U_005.dat           769.93 K                 774.74 K\n",
      "L_0.2U_006.dat           654.08 K                 657.56 K\n",
      "L_0.2U_007.dat           534.42 K                 538.15 K\n",
      "L_0.2U_008.dat           469.16 K                 472.69 K\n",
      "L_0.2U_009.dat           398.01 K                 400.26 K\n",
      "L_0.2U_010.dat           301.58 K                 301.60 K\n",
      "L_0.04S_000.dat          1238.27 K                1252.25 K\n",
      "L_0.04U_001.dat          1222.12 K                1235.73 K\n",
      "L_0.04U_002.dat          1202.14 K                1215.29 K\n",
      "L_0.04U_003.dat          1178.15 K                1190.80 K\n",
      "L_0.04U_004.dat          1151.07 K                1163.24 K\n",
      "L_0.04U_005.dat          1117.48 K                1129.17 K\n",
      "L_0.04U_006.dat          1078.64 K                1089.95 K\n",
      "L_0.04U_007.dat          1030.28 K                1041.43 K\n",
      "L_0.04U_008.dat          978.81 K                 990.16 K\n",
      "L_0.04U_009.dat          921.16 K                 933.21 K\n",
      "L_0.04U_010.dat          873.30 K                 885.68 K\n",
      "L_0.02S_000.dat          1252.91 K                1266.75 K\n",
      "L_0.02U_001.dat          1247.90 K                1261.63 K\n",
      "L_0.02U_002.dat          1241.59 K                1255.18 K\n",
      "L_0.02U_003.dat          1235.21 K                1248.68 K\n",
      "L_0.02U_004.dat          1226.71 K                1240.03 K\n",
      "L_0.02U_005.dat          1215.68 K                1228.85 K\n",
      "L_0.02U_006.dat          1202.53 K                1215.61 K\n",
      "L_0.02U_007.dat          1188.28 K                1201.34 K\n",
      "L_0.02U_008.dat          1168.12 K                1181.34 K\n",
      "L_0.02U_009.dat          1148.74 K                1162.26 K\n",
      "L_0.02U_010.dat          1130.17 K                1143.98 K\n",
      "L_0.008S_000.dat         1260.54 K                1273.92 K\n",
      "L_0.008U_001.dat         1259.69 K                1273.05 K\n",
      "L_0.008U_002.dat         1258.49 K                1271.83 K\n",
      "L_0.008U_003.dat         1256.86 K                1270.17 K\n",
      "L_0.008U_004.dat         1255.40 K                1268.69 K\n",
      "L_0.008U_005.dat         1253.42 K                1266.69 K\n",
      "L_0.008U_006.dat         1250.93 K                1264.19 K\n",
      "L_0.008U_007.dat         1247.85 K                1261.12 K\n",
      "L_0.008U_008.dat         1244.45 K                1257.75 K\n",
      "L_0.008U_009.dat         1240.87 K                1254.22 K\n",
      "L_0.008U_010.dat         1237.45 K                1250.86 K\n",
      "L_0.006S_000.dat         1256.30 K                1269.43 K\n",
      "L_0.006U_001.dat         1255.70 K                1268.83 K\n",
      "L_0.006U_002.dat         1255.07 K                1268.18 K\n",
      "L_0.006U_003.dat         1254.24 K                1267.33 K\n",
      "L_0.006U_004.dat         1253.19 K                1266.28 K\n",
      "L_0.006U_005.dat         1252.17 K                1265.25 K\n",
      "L_0.006U_006.dat         1250.92 K                1263.99 K\n",
      "L_0.006U_007.dat         1249.36 K                1262.43 K\n",
      "L_0.006U_008.dat         1247.62 K                1260.71 K\n",
      "L_0.006U_009.dat         1245.19 K                1258.30 K\n",
      "L_0.006U_010.dat         1242.92 K                1256.06 K\n",
      "L_0.004S_000.dat         1239.20 K                1251.86 K\n",
      "L_0.004U_001.dat         1238.88 K                1251.54 K\n",
      "L_0.004U_002.dat         1238.56 K                1251.21 K\n",
      "L_0.004U_003.dat         1238.16 K                1250.80 K\n",
      "L_0.004U_004.dat         1237.74 K                1250.38 K\n",
      "L_0.004U_005.dat         1237.14 K                1249.77 K\n",
      "L_0.004U_006.dat         1236.42 K                1249.06 K\n",
      "L_0.004U_007.dat         1235.78 K                1248.41 K\n",
      "L_0.004U_008.dat         1234.82 K                1247.45 K\n",
      "L_0.004U_009.dat         1233.84 K                1246.49 K\n",
      "L_0.004U_010.dat         1232.77 K                1245.43 K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_255/579430965.py:41: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  key = f'L_{length}{SU[time != 0]}_{zeros}{time}.dat'\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'L_0.002S_000.dat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 42\u001b[0m\n\u001b[1;32m     40\u001b[0m zeros \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m3\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mstr\u001b[39m(time)))\n\u001b[1;32m     41\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlength\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mSU[time \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzeros\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.dat\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 42\u001b[0m calculated \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mphiAvg[key]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m K\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m25\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(key))\u001b[38;5;241m+\u001b[39mcalculated\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m25\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(calculated))\u001b[38;5;241m+\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable[ximi][xivi][li][ti]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m K\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'L_0.002S_000.dat'"
     ]
    }
   ],
   "source": [
    "import LiuInt as LI\n",
    "\n",
    "#Set constants, get indices\n",
    "phi = 'T'\n",
    "ξm = 0.26\n",
    "ξv = 0.049575\n",
    "L = 0.002\n",
    "t = 9\n",
    "ximi, xivi, Li, ti = valToIndex(ξm, ξv, L, t, indices)\n",
    "\n",
    "#----- Example with one file and one phi\n",
    "#Manual Computation\n",
    "fileName = f'L_{L}U_00{t}.dat'\n",
    "file1_Tfunc = phiFuncs(\"/home/jaredwp91/Research/mnt/inferno/codes/flameNew/flame/run\", phi, fileName)\n",
    "phiAvg = LI.IntegrateForPhiBar(ξm, ξv, file1_Tfunc)\n",
    "print(f\"Average {phi} from data in {fileName} (calculated directly) = {phiAvg:.2f} K\")\n",
    "#Tabulated Values\n",
    "tableVal = table[ximi][xivi][Li][ti]\n",
    "print(f\"Average {phi} from data in {fileName} (tabulated)           = {tableVal:.2f} K\\n\")\n",
    "\n",
    "\n",
    "#----- Example with multiple files and one phi\n",
    "#Manual computation\n",
    "phiBarVector = np.vectorize(LI.IntegrateForPhiBar)\n",
    "file1_Tfunc = phiFuncs(\"/home/jaredwp91/Research/mnt/inferno/codes/flameNew/flame/run\", phi)\n",
    "phiAvg = {key: phiBarVector(ξm, ξv, file1_Tfunc[key]) for key in list(file1_Tfunc)}\n",
    "\n",
    "#----- Display Setup\n",
    "print(f\"Filename\"+\" \"*(21-len(\"Filename\"))+f\"{phi}_avg (calculated)\"+\" \"*8+f\"{phi}_avg (tabulated)\")\n",
    "print(\"----------------------------------------------------------------\")\n",
    "\n",
    "#----- Tabulated Values\n",
    "vals = []\n",
    "for i in range(len(indices[2])):\n",
    "    length = indices[2][i]\n",
    "    for j in range(len(indices[3])):\n",
    "        time = indices[3][j]\n",
    "        ximi, xivi, li, ti = valToIndex(ξm, ξv, length, time, indices)\n",
    "        SU = ['S', 'U']\n",
    "        zeros = \"0\"*(3-len(str(time)))\n",
    "        key = f'L_{length}{SU[time != 0]}_{zeros}{time}.dat'\n",
    "        calculated = f\"{phiAvg[key]:.2f} K\"\n",
    "        print(f\"{key}\"+\" \"*(25-len(key))+calculated+\" \"*(25-len(calculated))+f\"{table[ximi][xivi][li][ti]:.2f} K\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f07ea6-0b95-4b3b-b23e-ae44ea8640a2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Plotting, misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8468cf5f-5f86-402b-8fa4-bd44b963f153",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEBUGGING\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Set data to plot\n",
    "phi = 'T'\n",
    "fileIndex = 0\n",
    "\n",
    "#Grab data\n",
    "phiBarFuncs = phiFuncs(\"/home/jaredwp91/Research/mnt/inferno/codes/flameNew/flame/run\", phi)\n",
    "\n",
    "#Print availlable files list\n",
    "#filenames_with_index = []\n",
    "print(\"Available Files:\")\n",
    "names = [key for key in phiBarFuncs.keys()]\n",
    "for i in range(len(names)):\n",
    "    print(i,\" \", names[i])\n",
    "\n",
    "#Plot data\n",
    "Xiplt = np.linspace(0,1,500)\n",
    "plt.plot(Xiplt, phiBarFuncs[names[fileIndex]](Xiplt))\n",
    "plt.title(names[fileIndex])\n",
    "plt.xlabel('xi')\n",
    "plt.ylabel(phi);\n",
    "#get_data_files(\"/home/jaredwp91/Research/mnt/inferno/codes/flameJWP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a6db43-35df-42c8-9750-885d5d157730",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
